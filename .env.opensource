# LEX Open Source Configuration
# No paid APIs - Local models only

# Disable all paid services
OPENAI_API_KEY=disabled
ANTHROPIC_API_KEY=disabled
TOGETHER_API_KEY=disabled
GROQ_API_KEY=disabled
DEEPSEEK_API_KEY=disabled
REPLICATE_API_KEY=disabled
STABILITY_API_KEY=disabled
ELEVENLABS_API_KEY=disabled

# Local model configuration
OLLAMA_HOST=http://localhost:11434
USE_LOCAL_MODELS=true
LOCAL_ONLY_MODE=true

# GPU settings
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_FRACTION=0.95

# Model preferences
PRIMARY_MODEL=dolphin-mixtral:latest
FALLBACK_MODEL=mixtral:8x7b-instruct-v0.1-q4_K_M
FAST_MODEL=neural-chat:7b

# Performance
MODEL_TIMEOUT=300
MAX_TOKENS=2000
TEMPERATURE=0.8

# Privacy
LOG_QUERIES=false
SEND_TELEMETRY=false
OFFLINE_MODE=true