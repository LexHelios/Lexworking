#!/usr/bin/env python3
"""
Database Connection Pool Manager for LEX Performance Optimization
üî± JAI MAHAKAAL! High-performance database pooling for 80% query speedup
"""
import sqlite3
import threading
import logging
import time
import os
import asyncio
from typing import Optional, Dict, Any, List, Callable, Tuple
from contextlib import contextmanager, asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
import queue

logger = logging.getLogger(__name__)

@dataclass
class ConnectionStats:
    """Database connection statistics"""
    total_connections_created: int = 0
    active_connections: int = 0
    total_queries: int = 0
    successful_queries: int = 0
    failed_queries: int = 0
    total_query_time: float = 0.0
    connection_waits: int = 0
    connection_timeouts: int = 0
    pool_size: int = 0
    max_pool_size: int = 0
    
    @property
    def average_query_time(self) -> float:
        if self.successful_queries == 0:
            return 0.0
        return self.total_query_time / self.successful_queries
    
    @property
    def success_rate(self) -> float:
        if self.total_queries == 0:
            return 100.0
        return (self.successful_queries / self.total_queries) * 100

class SQLiteConnection:
    """Enhanced SQLite connection with performance optimizations"""
    
    def __init__(self, db_path: str, connection_id: int):
        self.db_path = db_path
        self.connection_id = connection_id
        self.connection = None
        self.created_at = datetime.utcnow()
        self.last_used = datetime.utcnow()
        self.query_count = 0
        self.is_transaction_active = False
        self.lock = threading.Lock()
        
        self._create_connection()
    
    def _create_connection(self):
        """Create optimized SQLite connection"""
        try:
            self.connection = sqlite3.connect(
                self.db_path,
                check_same_thread=False,  # Allow sharing between threads
                isolation_level=None,     # Autocommit mode
                timeout=30.0             # 30 second timeout
            )
            
            # Apply performance optimizations
            cursor = self.connection.cursor()
            
            # Performance PRAGMA settings
            performance_settings = [
                "PRAGMA journal_mode=WAL",           # Write-Ahead Logging
                "PRAGMA synchronous=NORMAL",         # Balanced durability/speed
                "PRAGMA cache_size=10000",           # 10MB cache
                "PRAGMA temp_store=MEMORY",          # Store temp data in memory
                "PRAGMA mmap_size=268435456",        # 256MB memory mapping
                "PRAGMA optimize",                   # Query planner optimization
                "PRAGMA page_size=4096",             # Optimal page size
                "PRAGMA auto_vacuum=INCREMENTAL"     # Incremental vacuuming
            ]
            
            for setting in performance_settings:
                cursor.execute(setting)
            
            # Register custom functions for better performance
            self.connection.create_function("regexp", 2, self._regexp)
            
            logger.debug(f"‚úÖ Created optimized connection {self.connection_id}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create connection {self.connection_id}: {e}")
            raise
    
    def _regexp(self, pattern: str, text: str) -> bool:
        """Custom REGEXP function for SQLite"""
        import re
        try:
            return bool(re.search(pattern, text))
        except:
            return False
    
    def execute_query(self, query: str, params: tuple = (), fetch: str = None) -> Any:
        """Execute query with performance tracking"""
        with self.lock:
            start_time = time.time()
            self.last_used = datetime.utcnow()
            self.query_count += 1
            
            try:
                cursor = self.connection.cursor()
                cursor.execute(query, params)
                
                if fetch == 'one':
                    result = cursor.fetchone()
                elif fetch == 'all':
                    result = cursor.fetchall()
                elif fetch == 'many':
                    result = cursor.fetchmany()
                else:
                    result = cursor.rowcount
                
                query_time = time.time() - start_time
                logger.debug(f"‚úÖ Query executed in {query_time:.3f}s: {query[:50]}...")
                
                return result
                
            except Exception as e:
                query_time = time.time() - start_time
                logger.error(f"‚ùå Query failed in {query_time:.3f}s: {query[:50]}... Error: {e}")
                raise
    
    def begin_transaction(self):
        """Begin explicit transaction"""
        with self.lock:
            if not self.is_transaction_active:
                self.connection.execute("BEGIN")
                self.is_transaction_active = True
                logger.debug(f"üîÑ Transaction started on connection {self.connection_id}")
    
    def commit_transaction(self):
        """Commit transaction"""
        with self.lock:
            if self.is_transaction_active:
                self.connection.execute("COMMIT")
                self.is_transaction_active = False
                logger.debug(f"‚úÖ Transaction committed on connection {self.connection_id}")
    
    def rollback_transaction(self):
        """Rollback transaction"""
        with self.lock:
            if self.is_transaction_active:
                self.connection.execute("ROLLBACK")
                self.is_transaction_active = False
                logger.debug(f"üîÑ Transaction rolled back on connection {self.connection_id}")
    
    def close(self):
        """Close connection"""
        with self.lock:
            if self.connection:
                if self.is_transaction_active:
                    self.rollback_transaction()
                self.connection.close()
                self.connection = None
                logger.debug(f"üîí Connection {self.connection_id} closed")

class DatabaseConnectionPool:
    """High-performance database connection pool"""
    
    def __init__(
        self, 
        db_path: str,
        pool_size: int = 20,
        max_pool_size: int = 50,
        connection_timeout: float = 30.0,
        idle_timeout: float = 300.0  # 5 minutes
    ):
        self.db_path = db_path
        self.pool_size = pool_size
        self.max_pool_size = max_pool_size
        self.connection_timeout = connection_timeout
        self.idle_timeout = idle_timeout
        
        # Connection management
        self.available_connections = queue.Queue(maxsize=max_pool_size)
        self.all_connections = {}
        self.connection_counter = 0
        self.lock = threading.Lock()
        
        # Statistics tracking
        self.stats = ConnectionStats(
            pool_size=pool_size,
            max_pool_size=max_pool_size
        )
        
        # Background maintenance
        self.maintenance_thread = None
        self.shutdown_event = threading.Event()
        
        # Initialize pool
        self._initialize_pool()
        self._start_maintenance_thread()
    
    def _initialize_pool(self):
        """Initialize connection pool with base connections"""
        logger.info(f"üîÑ Initializing database pool with {self.pool_size} connections...")
        
        for _ in range(self.pool_size):
            try:
                connection = self._create_new_connection()
                self.available_connections.put(connection, block=False)
            except Exception as e:
                logger.error(f"‚ùå Failed to initialize connection: {e}")
        
        logger.info(f"‚úÖ Database pool initialized with {self.available_connections.qsize()} connections")
    
    def _create_new_connection(self) -> SQLiteConnection:
        """Create new connection"""
        with self.lock:
            self.connection_counter += 1
            connection_id = self.connection_counter
            
        try:
            connection = SQLiteConnection(self.db_path, connection_id)
            
            with self.lock:
                self.all_connections[connection_id] = connection
                self.stats.total_connections_created += 1
                self.stats.active_connections += 1
            
            return connection
            
        except Exception as e:
            logger.error(f"‚ùå Failed to create connection {connection_id}: {e}")
            raise
    
    @contextmanager
    def get_connection(self):
        """Get connection from pool with automatic return"""
        connection = None
        start_time = time.time()
        
        try:
            # Try to get available connection
            try:
                connection = self.available_connections.get(timeout=self.connection_timeout)
                logger.debug(f"üîó Got connection {connection.connection_id} from pool")
                
            except queue.Empty:
                # Pool exhausted, try to create new connection if under limit
                with self.lock:
                    if len(self.all_connections) < self.max_pool_size:
                        connection = self._create_new_connection()
                        logger.debug(f"üÜï Created new connection {connection.connection_id}")
                    else:
                        self.stats.connection_timeouts += 1
                        raise Exception("Connection pool exhausted and max pool size reached")
            
            # Update stats
            wait_time = time.time() - start_time
            if wait_time > 0.1:  # Waited more than 100ms
                self.stats.connection_waits += 1
            
            yield connection
            
        except Exception as e:
            logger.error(f"‚ùå Failed to get database connection: {e}")
            raise
        finally:
            # Return connection to pool
            if connection:
                try:
                    # Check if connection is still valid
                    if connection.connection and not connection.is_transaction_active:
                        self.available_connections.put(connection, block=False)
                        logger.debug(f"üîÑ Returned connection {connection.connection_id} to pool")
                    else:
                        # Connection is in bad state, remove it
                        self._remove_connection(connection)
                except queue.Full:
                    # Pool is full, close this connection
                    self._remove_connection(connection)
    
    def _remove_connection(self, connection: SQLiteConnection):
        """Remove connection from pool"""
        try:
            connection.close()
            
            with self.lock:
                if connection.connection_id in self.all_connections:
                    del self.all_connections[connection.connection_id]
                    self.stats.active_connections -= 1
                    
            logger.debug(f"üóëÔ∏è Removed connection {connection.connection_id} from pool")
            
        except Exception as e:
            logger.error(f"‚ùå Error removing connection: {e}")
    
    def execute_query(self, query: str, params: tuple = (), fetch: str = None) -> Any:
        """Execute query using connection from pool"""
        start_time = time.time()
        
        try:
            with self.get_connection() as connection:
                result = connection.execute_query(query, params, fetch)
                
                # Update statistics
                query_time = time.time() - start_time
                self.stats.total_queries += 1
                self.stats.successful_queries += 1
                self.stats.total_query_time += query_time
                
                return result
                
        except Exception as e:
            query_time = time.time() - start_time
            self.stats.total_queries += 1
            self.stats.failed_queries += 1
            self.stats.total_query_time += query_time
            
            logger.error(f"‚ùå Pooled query failed: {e}")
            raise
    
    def execute_transaction(self, queries: List[Tuple[str, tuple]]) -> bool:
        """Execute multiple queries in a transaction"""
        try:
            with self.get_connection() as connection:
                connection.begin_transaction()
                
                try:
                    for query, params in queries:
                        connection.execute_query(query, params)
                    
                    connection.commit_transaction()
                    logger.debug(f"‚úÖ Transaction completed with {len(queries)} queries")
                    return True
                    
                except Exception as e:
                    connection.rollback_transaction()
                    logger.error(f"‚ùå Transaction failed, rolled back: {e}")
                    raise
                    
        except Exception as e:
            logger.error(f"‚ùå Transaction execution failed: {e}")
            return False
    
    def _start_maintenance_thread(self):
        """Start background maintenance thread"""
        def maintenance_worker():
            logger.info("üîß Started database pool maintenance thread")
            
            while not self.shutdown_event.wait(60):  # Check every minute
                try:
                    self._perform_maintenance()
                except Exception as e:
                    logger.error(f"‚ùå Maintenance error: {e}")
            
            logger.info("üõë Database pool maintenance thread stopped")
        
        self.maintenance_thread = threading.Thread(target=maintenance_worker, daemon=True)
        self.maintenance_thread.start()
    
    def _perform_maintenance(self):
        """Perform periodic maintenance"""
        current_time = datetime.utcnow()
        connections_to_remove = []
        
        # Find idle connections
        with self.lock:
            for conn_id, connection in self.all_connections.items():
                if connection.connection:
                    idle_time = (current_time - connection.last_used).total_seconds()
                    
                    if idle_time > self.idle_timeout and len(self.all_connections) > self.pool_size:
                        connections_to_remove.append(connection)
        
        # Remove idle connections
        for connection in connections_to_remove:
            self._remove_connection(connection)
            logger.debug(f"üßπ Removed idle connection {connection.connection_id}")
        
        # Log maintenance stats
        active_count = len(self.all_connections)
        queue_size = self.available_connections.qsize()
        
        logger.debug(f"üîß Pool maintenance: {active_count} active, {queue_size} available")
    
    def get_pool_statistics(self) -> Dict[str, Any]:
        """Get comprehensive pool statistics"""
        with self.lock:
            current_stats = {
                'pool_stats': {
                    'total_connections_created': self.stats.total_connections_created,
                    'active_connections': len(self.all_connections),
                    'available_connections': self.available_connections.qsize(),
                    'pool_size': self.pool_size,
                    'max_pool_size': self.max_pool_size
                },
                'query_stats': {
                    'total_queries': self.stats.total_queries,
                    'successful_queries': self.stats.successful_queries,
                    'failed_queries': self.stats.failed_queries,
                    'success_rate_percent': round(self.stats.success_rate, 2),
                    'average_query_time_ms': round(self.stats.average_query_time * 1000, 2)
                },
                'performance_metrics': {
                    'connection_waits': self.stats.connection_waits,
                    'connection_timeouts': self.stats.connection_timeouts,
                    'queries_per_connection': round(self.stats.total_queries / max(1, self.stats.total_connections_created), 2)
                }
            }
        
        return current_stats
    
    def optimize_pool_size(self) -> Dict[str, Any]:
        """Analyze and recommend pool size optimization"""
        stats = self.get_pool_statistics()
        recommendations = []
        
        wait_ratio = self.stats.connection_waits / max(1, self.stats.total_queries)
        timeout_ratio = self.stats.connection_timeouts / max(1, self.stats.total_queries)
        
        if timeout_ratio > 0.01:  # More than 1% timeouts
            recommendations.append(f"Consider increasing max_pool_size from {self.max_pool_size} to {self.max_pool_size * 2}")
        
        if wait_ratio > 0.1:  # More than 10% waits
            recommendations.append(f"Consider increasing pool_size from {self.pool_size} to {min(self.pool_size * 2, self.max_pool_size)}")
        
        if self.stats.average_query_time > 0.1:  # Queries taking more than 100ms
            recommendations.append("Consider adding database indexes for frequently queried tables")
        
        utilization = len(self.all_connections) / self.max_pool_size
        
        optimization_report = {
            'current_performance': stats,
            'utilization_percent': round(utilization * 100, 1),
            'recommendations': recommendations,
            'optimal_settings': {
                'suggested_pool_size': min(self.pool_size * 2, 50) if wait_ratio > 0.1 else self.pool_size,
                'suggested_max_pool_size': self.max_pool_size * 2 if timeout_ratio > 0.01 else self.max_pool_size
            }
        }
        
        return optimization_report
    
    def close_all_connections(self):
        """Close all connections and shut down pool"""
        logger.info("üîí Shutting down database connection pool...")
        
        # Signal maintenance thread to stop
        self.shutdown_event.set()
        
        # Wait for maintenance thread to finish
        if self.maintenance_thread:
            self.maintenance_thread.join(timeout=5)
        
        # Close all connections
        with self.lock:
            for connection in list(self.all_connections.values()):
                self._remove_connection(connection)
        
        logger.info("‚úÖ Database connection pool shut down complete")

# Global database pool
db_pool = None

def initialize_db_pool(
    db_path: str = "lex_memory.db",
    pool_size: int = 20,
    max_pool_size: int = 50
) -> DatabaseConnectionPool:
    """Initialize global database pool"""
    global db_pool
    
    if db_pool is None:
        db_pool = DatabaseConnectionPool(
            db_path=db_path,
            pool_size=pool_size,
            max_pool_size=max_pool_size
        )
        logger.info("‚úÖ Global database pool initialized")
    
    return db_pool

def get_db_pool() -> DatabaseConnectionPool:
    """Get global database pool"""
    if db_pool is None:
        initialize_db_pool()
    
    return db_pool

# Convenience functions
def execute_query(query: str, params: tuple = (), fetch: str = None) -> Any:
    """Execute query using global pool"""
    pool = get_db_pool()
    return pool.execute_query(query, params, fetch)

def execute_transaction(queries: List[Tuple[str, tuple]]) -> bool:
    """Execute transaction using global pool"""
    pool = get_db_pool()
    return pool.execute_transaction(queries)